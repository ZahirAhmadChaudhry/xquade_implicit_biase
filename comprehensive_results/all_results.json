{
  "baseline": {
    "en": {
      "seed_42": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "en",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7414637307015558,
        "std_semantic_similarity": 0.2533351132069908,
        "avg_bertscore_f1": 0.9082527428865432,
        "std_bertscore_f1": 0.07246826593678736,
        "avg_exact_match": 0.35,
        "std_exact_match": 0.47696960070847283,
        "avg_token_f1": 0.5707875355566256,
        "std_token_f1": 0.37080999205321413,
        "avg_rouge_l": 0.5721298411841415,
        "std_rouge_l": 0.37474733930138165
      },
      "seed_59": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "en",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7765079173569878,
        "std_semantic_similarity": 0.23275489987393425,
        "avg_bertscore_f1": 0.9164270284275214,
        "std_bertscore_f1": 0.06938423496341263,
        "avg_exact_match": 0.38333333333333336,
        "std_exact_match": 0.48619840486049404,
        "avg_token_f1": 0.6042545624310055,
        "std_token_f1": 0.36374515211050246,
        "avg_rouge_l": 0.6201728206575372,
        "std_rouge_l": 0.36291511872315857
      },
      "seed_76": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "en",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7674364040295283,
        "std_semantic_similarity": 0.239519509168464,
        "avg_bertscore_f1": 0.911038053035736,
        "std_bertscore_f1": 0.07064378386360726,
        "avg_exact_match": 0.3541666666666667,
        "std_exact_match": 0.4782600118020414,
        "avg_token_f1": 0.6027999987526987,
        "std_token_f1": 0.3617658213469404,
        "avg_rouge_l": 0.6110543922188468,
        "std_rouge_l": 0.363739049250669
      }
    },
    "es": {
      "seed_42": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "es",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6313966954126954,
        "std_semantic_similarity": 0.22036086094058951,
        "avg_bertscore_f1": 0.8612575421730677,
        "std_bertscore_f1": 0.06069004640935331,
        "avg_exact_match": 0.14583333333333334,
        "std_exact_match": 0.3529390488770296,
        "avg_token_f1": 0.3903722204444948,
        "std_token_f1": 0.3063899931685152,
        "avg_rouge_l": 0.399462359671027,
        "std_rouge_l": 0.30821030458810306
      },
      "seed_59": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "es",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6072753918512414,
        "std_semantic_similarity": 0.21043813835440728,
        "avg_bertscore_f1": 0.8587007676561673,
        "std_bertscore_f1": 0.056870119505058804,
        "avg_exact_match": 0.09583333333333334,
        "std_exact_match": 0.2943625410196677,
        "avg_token_f1": 0.36308874409663106,
        "std_token_f1": 0.2760590561985219,
        "avg_rouge_l": 0.37351932389027276,
        "std_rouge_l": 0.2834316964253016
      },
      "seed_76": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "es",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6168285960331559,
        "std_semantic_similarity": 0.2118784652199085,
        "avg_bertscore_f1": 0.857416416456302,
        "std_bertscore_f1": 0.05780542372164871,
        "avg_exact_match": 0.09583333333333334,
        "std_exact_match": 0.2943625410196677,
        "avg_token_f1": 0.3729176105333913,
        "std_token_f1": 0.29306593227474964,
        "avg_rouge_l": 0.3805903429055288,
        "std_rouge_l": 0.2969875106681725
      }
    },
    "th": {
      "seed_42": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "th",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.608775897603482,
        "std_semantic_similarity": 0.2286737436933271,
        "avg_bertscore_f1": 0.8851809032261372,
        "std_bertscore_f1": 0.06140041512759009,
        "avg_exact_match": 0.1125,
        "std_exact_match": 0.31598061649411346,
        "avg_token_f1": 0.39845773540948987,
        "std_token_f1": 0.3340679853347178,
        "avg_rouge_l": 0.21185780654530656,
        "std_rouge_l": 0.38261052784903155
      },
      "seed_59": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "th",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.5881132654535274,
        "std_semantic_similarity": 0.21222304501563266,
        "avg_bertscore_f1": 0.8792202624181906,
        "std_bertscore_f1": 0.058103746885634536,
        "avg_exact_match": 0.075,
        "std_exact_match": 0.2633913438213185,
        "avg_token_f1": 0.37872161655550135,
        "std_token_f1": 0.3143047083031503,
        "avg_rouge_l": 0.2350321669071669,
        "std_rouge_l": 0.39128400636605776
      },
      "seed_76": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "th",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6219357434349756,
        "std_semantic_similarity": 0.2203000334063123,
        "avg_bertscore_f1": 0.8861165029307206,
        "std_bertscore_f1": 0.060468033354661374,
        "avg_exact_match": 0.10416666666666667,
        "std_exact_match": 0.3054766312211496,
        "avg_token_f1": 0.3897548724317363,
        "std_token_f1": 0.34120238577150386,
        "avg_rouge_l": 0.20980056163879693,
        "std_rouge_l": 0.3830686519796124
      }
    },
    "ar": {
      "seed_42": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "ar",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.641468789242208,
        "std_semantic_similarity": 0.2431008513224012,
        "avg_bertscore_f1": 0.8753655220071475,
        "std_bertscore_f1": 0.056833663887584304,
        "avg_exact_match": 0.1625,
        "std_exact_match": 0.36890886408434265,
        "avg_token_f1": 0.4154750209807558,
        "std_token_f1": 0.32248409033578834,
        "avg_rouge_l": 0.16319444444444445,
        "std_rouge_l": 0.3533726120288594
      },
      "seed_59": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "ar",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6439805325741569,
        "std_semantic_similarity": 0.2363443746190189,
        "avg_bertscore_f1": 0.8729249484837055,
        "std_bertscore_f1": 0.06054502099176399,
        "avg_exact_match": 0.15416666666666667,
        "std_exact_match": 0.36110844016106236,
        "avg_token_f1": 0.40379792043503904,
        "std_token_f1": 0.321387431977992,
        "avg_rouge_l": 0.1796990740740741,
        "std_rouge_l": 0.3620863426392822
      },
      "seed_76": {
        "config_name": "baseline",
        "config_description": "No-Tag_0-shot",
        "language": "ar",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6365956944103043,
        "std_semantic_similarity": 0.22483960449806917,
        "avg_bertscore_f1": 0.8706140105923017,
        "std_bertscore_f1": 0.058669842786646234,
        "avg_exact_match": 0.12083333333333333,
        "std_exact_match": 0.3259334884434075,
        "avg_token_f1": 0.40008580984763514,
        "std_token_f1": 0.3073869376376372,
        "avg_rouge_l": 0.19137313258636787,
        "std_rouge_l": 0.37716102513961286
      }
    }
  },
  "bracket_prefix": {
    "en": {
      "seed_42": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "en",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7555858042401572,
        "std_semantic_similarity": 0.25271194285486315,
        "avg_bertscore_f1": 0.9127498346070448,
        "std_bertscore_f1": 0.07231531928200519,
        "avg_exact_match": 0.37916666666666665,
        "std_exact_match": 0.485179663171856,
        "avg_token_f1": 0.5859475443308485,
        "std_token_f1": 0.3749122279357016,
        "avg_rouge_l": 0.587763288711294,
        "std_rouge_l": 0.37801843163926163
      },
      "seed_59": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "en",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.794059565430507,
        "std_semantic_similarity": 0.23469808594707764,
        "avg_bertscore_f1": 0.9226567765076955,
        "std_bertscore_f1": 0.06921010420171149,
        "avg_exact_match": 0.42083333333333334,
        "std_exact_match": 0.49369285885952296,
        "avg_token_f1": 0.6309875002581293,
        "std_token_f1": 0.3666752773428553,
        "avg_rouge_l": 0.6468815647814172,
        "std_rouge_l": 0.3665421834425439
      },
      "seed_76": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "en",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7841540282902618,
        "std_semantic_similarity": 0.23722960950319275,
        "avg_bertscore_f1": 0.9131388699014982,
        "std_bertscore_f1": 0.07119303400088471,
        "avg_exact_match": 0.38333333333333336,
        "std_exact_match": 0.48619840486049404,
        "avg_token_f1": 0.6169516711214549,
        "std_token_f1": 0.36627309087721494,
        "avg_rouge_l": 0.6253311439889511,
        "std_rouge_l": 0.367809416679992
      }
    },
    "es": {
      "seed_42": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "es",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6996847808050612,
        "std_semantic_similarity": 0.23625534718455588,
        "avg_bertscore_f1": 0.8828476622700692,
        "std_bertscore_f1": 0.06879581486423632,
        "avg_exact_match": 0.25,
        "std_exact_match": 0.4330127018922193,
        "avg_token_f1": 0.4874764273356026,
        "std_token_f1": 0.3582243725846391,
        "avg_rouge_l": 0.4949416663395438,
        "std_rouge_l": 0.35688829544524775
      },
      "seed_59": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "es",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6828803331280748,
        "std_semantic_similarity": 0.2351254183735008,
        "avg_bertscore_f1": 0.8783921731015046,
        "std_bertscore_f1": 0.06553417009293963,
        "avg_exact_match": 0.19166666666666668,
        "std_exact_match": 0.39361218928731817,
        "avg_token_f1": 0.4601256302856253,
        "std_token_f1": 0.33264522283792375,
        "avg_rouge_l": 0.469835745483603,
        "std_rouge_l": 0.3384341443121212
      },
      "seed_76": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "es",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6996849539379278,
        "std_semantic_similarity": 0.22752206149002058,
        "avg_bertscore_f1": 0.8800313368439674,
        "std_bertscore_f1": 0.0648680802724346,
        "avg_exact_match": 0.20416666666666666,
        "std_exact_match": 0.4030913530316532,
        "avg_token_f1": 0.47173631268589017,
        "std_token_f1": 0.34586675765997915,
        "avg_rouge_l": 0.48170946054188873,
        "std_rouge_l": 0.3451158071502544
      }
    },
    "th": {
      "seed_42": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "th",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.702841199748218,
        "std_semantic_similarity": 0.23743159758404836,
        "avg_bertscore_f1": 0.901515640815099,
        "std_bertscore_f1": 0.06653677220951042,
        "avg_exact_match": 0.2125,
        "std_exact_match": 0.40907670429883924,
        "avg_token_f1": 0.4323625489103832,
        "std_token_f1": 0.3766922915395357,
        "avg_rouge_l": 0.216351848687375,
        "std_rouge_l": 0.3856538261846585
      },
      "seed_59": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "th",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6850627245381474,
        "std_semantic_similarity": 0.22226503445596457,
        "avg_bertscore_f1": 0.8937551779051621,
        "std_bertscore_f1": 0.0643856784290954,
        "avg_exact_match": 0.15833333333333333,
        "std_exact_match": 0.36505326856349185,
        "avg_token_f1": 0.42085180644999465,
        "std_token_f1": 0.34591782699432927,
        "avg_rouge_l": 0.21846396658896658,
        "std_rouge_l": 0.37173748552551383
      },
      "seed_76": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "th",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7059024155139924,
        "std_semantic_similarity": 0.2346567468062202,
        "avg_bertscore_f1": 0.8986645467579365,
        "std_bertscore_f1": 0.06706520680518228,
        "avg_exact_match": 0.20416666666666666,
        "std_exact_match": 0.4030913530316532,
        "avg_token_f1": 0.4304326551268793,
        "std_token_f1": 0.3744969994872432,
        "avg_rouge_l": 0.1798673328305681,
        "std_rouge_l": 0.34442190947554246
      }
    },
    "ar": {
      "seed_42": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "ar",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7052748213832577,
        "std_semantic_similarity": 0.24490049732491628,
        "avg_bertscore_f1": 0.8831792863706748,
        "std_bertscore_f1": 0.06326842460933718,
        "avg_exact_match": 0.2708333333333333,
        "std_exact_match": 0.44439018766044885,
        "avg_token_f1": 0.49758256963628505,
        "std_token_f1": 0.36832222075625626,
        "avg_rouge_l": 0.15058321308321307,
        "std_rouge_l": 0.33521047751327215
      },
      "seed_59": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "ar",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7204276630654931,
        "std_semantic_similarity": 0.23987090333455446,
        "avg_bertscore_f1": 0.878010659913222,
        "std_bertscore_f1": 0.0639829291551769,
        "avg_exact_match": 0.23333333333333334,
        "std_exact_match": 0.4229525846816507,
        "avg_token_f1": 0.4865100113254381,
        "std_token_f1": 0.35947433507024834,
        "avg_rouge_l": 0.1664066257816258,
        "std_rouge_l": 0.3425491617998847
      },
      "seed_76": {
        "config_name": "bracket_prefix",
        "config_description": "bracket-prefix_0-shot",
        "language": "ar",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7219179558878144,
        "std_semantic_similarity": 0.22346063841701255,
        "avg_bertscore_f1": 0.878129809598128,
        "std_bertscore_f1": 0.06340599039653012,
        "avg_exact_match": 0.2375,
        "std_exact_match": 0.42555111326373,
        "avg_token_f1": 0.5099947654982612,
        "std_token_f1": 0.3529392270148424,
        "avg_rouge_l": 0.1661837421837422,
        "std_rouge_l": 0.34371873941041664
      }
    }
  },
  "few_shot_2": {
    "en": {
      "seed_42": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "en",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.9004946237429976,
        "std_semantic_similarity": 0.1967745968575967,
        "avg_bertscore_f1": 0.9606016151607036,
        "std_bertscore_f1": 0.05849532057189611,
        "avg_exact_match": 0.6125,
        "std_exact_match": 0.48717938174762687,
        "avg_token_f1": 0.8149148296145846,
        "std_token_f1": 0.2925909771232388,
        "avg_rouge_l": 0.8204028576700145,
        "std_rouge_l": 0.2940552720115798
      },
      "seed_59": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "en",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.9309154090782007,
        "std_semantic_similarity": 0.15272832486959445,
        "avg_bertscore_f1": 0.9684208127359549,
        "std_bertscore_f1": 0.04907469688251536,
        "avg_exact_match": 0.675,
        "std_exact_match": 0.4683748498798798,
        "avg_token_f1": 0.8539199032846376,
        "std_token_f1": 0.2606129029674441,
        "avg_rouge_l": 0.8673603212753604,
        "std_rouge_l": 0.25491618946222505
      },
      "seed_76": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "en",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.9339429058134556,
        "std_semantic_similarity": 0.1516688170311284,
        "avg_bertscore_f1": 0.9690479243795077,
        "std_bertscore_f1": 0.05215106883645917,
        "avg_exact_match": 0.6916666666666667,
        "std_exact_match": 0.4618050334165803,
        "avg_token_f1": 0.8593484675584079,
        "std_token_f1": 0.257298038372612,
        "avg_rouge_l": 0.8691782020975722,
        "std_rouge_l": 0.2521781441416331
      }
    },
    "es": {
      "seed_42": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "es",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.8923771804819505,
        "std_semantic_similarity": 0.18790204147445294,
        "avg_bertscore_f1": 0.9480177516738574,
        "std_bertscore_f1": 0.06125237752348205,
        "avg_exact_match": 0.49166666666666664,
        "std_exact_match": 0.49993055073235465,
        "avg_token_f1": 0.7848969415813793,
        "std_token_f1": 0.2853622393367289,
        "avg_rouge_l": 0.7983770003064399,
        "std_rouge_l": 0.28339044428814636
      },
      "seed_59": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "es",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.9164796313891809,
        "std_semantic_similarity": 0.17029457169762116,
        "avg_bertscore_f1": 0.9580508500337601,
        "std_bertscore_f1": 0.05909465549777449,
        "avg_exact_match": 0.6125,
        "std_exact_match": 0.48717938174762687,
        "avg_token_f1": 0.8160520892091147,
        "std_token_f1": 0.28151596295544146,
        "avg_rouge_l": 0.8317581966444695,
        "std_rouge_l": 0.28670230368440475
      },
      "seed_76": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "es",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.9146404535199205,
        "std_semantic_similarity": 0.15516644013033912,
        "avg_bertscore_f1": 0.9580914964278539,
        "std_bertscore_f1": 0.05899615886270716,
        "avg_exact_match": 0.6083333333333333,
        "std_exact_match": 0.48812282152024905,
        "avg_token_f1": 0.8126070483846923,
        "std_token_f1": 0.28919963309524793,
        "avg_rouge_l": 0.8263263742073611,
        "std_rouge_l": 0.29026768216832954
      }
    },
    "th": {
      "seed_42": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "th",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.8989078675707182,
        "std_semantic_similarity": 0.19719148574981524,
        "avg_bertscore_f1": 0.962942503641049,
        "std_bertscore_f1": 0.061144210423783776,
        "avg_exact_match": 0.65,
        "std_exact_match": 0.47696960070847283,
        "avg_token_f1": 0.7787544209603033,
        "std_token_f1": 0.365691391313434,
        "avg_rouge_l": 0.24194444444444443,
        "std_rouge_l": 0.4260063430525273
      },
      "seed_59": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "th",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.9125018006811539,
        "std_semantic_similarity": 0.18999143887408573,
        "avg_bertscore_f1": 0.9683369867503643,
        "std_bertscore_f1": 0.05622317462093986,
        "avg_exact_match": 0.6833333333333333,
        "std_exact_match": 0.4651761912317621,
        "avg_token_f1": 0.7952380068188892,
        "std_token_f1": 0.35443416595536925,
        "avg_rouge_l": 0.28145833333333337,
        "std_rouge_l": 0.44498746666182754
      },
      "seed_76": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "th",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.9261898233244816,
        "std_semantic_similarity": 0.16248174088654532,
        "avg_bertscore_f1": 0.9745913696785767,
        "std_bertscore_f1": 0.046954806074254604,
        "avg_exact_match": 0.7208333333333333,
        "std_exact_match": 0.4485896107678921,
        "avg_token_f1": 0.7996930615680616,
        "std_token_f1": 0.3609696039980682,
        "avg_rouge_l": 0.24155092592592592,
        "std_rouge_l": 0.4262659516090868
      }
    },
    "ar": {
      "seed_42": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "ar",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.878394036864241,
        "std_semantic_similarity": 0.19968251526793585,
        "avg_bertscore_f1": 0.9529429545005162,
        "std_bertscore_f1": 0.058721238125908695,
        "avg_exact_match": 0.525,
        "std_exact_match": 0.4993746088859544,
        "avg_token_f1": 0.7525170731627713,
        "std_token_f1": 0.32744278953412453,
        "avg_rouge_l": 0.1798611111111111,
        "std_rouge_l": 0.3815016372551958
      },
      "seed_59": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "ar",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.9026221244906386,
        "std_semantic_similarity": 0.18909347824168454,
        "avg_bertscore_f1": 0.9555390087266763,
        "std_bertscore_f1": 0.06143503380362082,
        "avg_exact_match": 0.5708333333333333,
        "std_exact_match": 0.49495720914932534,
        "avg_token_f1": 0.7570008349946556,
        "std_token_f1": 0.35343280897700396,
        "avg_rouge_l": 0.19826388888888888,
        "std_rouge_l": 0.394056532407502
      },
      "seed_76": {
        "config_name": "few_shot_2",
        "config_description": "bracket-prefix_2-shot",
        "language": "ar",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.8998067317530513,
        "std_semantic_similarity": 0.18621243460456982,
        "avg_bertscore_f1": 0.9580724209547042,
        "std_bertscore_f1": 0.055794835566313435,
        "avg_exact_match": 0.575,
        "std_exact_match": 0.4943429983321297,
        "avg_token_f1": 0.7680869796003814,
        "std_token_f1": 0.33301690528898903,
        "avg_rouge_l": 0.21215277777777777,
        "std_rouge_l": 0.4054566981397126
      }
    }
  },
  "incorrect_tag": {
    "en": {
      "seed_42": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "en",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7150268063570062,
        "std_semantic_similarity": 0.2475361477281936,
        "avg_bertscore_f1": 0.885974686096112,
        "std_bertscore_f1": 0.07938489800425727,
        "avg_exact_match": 0.275,
        "std_exact_match": 0.44651427748729383,
        "avg_token_f1": 0.43738986817685094,
        "std_token_f1": 0.4114905834175139,
        "avg_rouge_l": 0.4384795859605469,
        "std_rouge_l": 0.414932762656011
      },
      "seed_59": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "en",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7618543785065413,
        "std_semantic_similarity": 0.22705748725565586,
        "avg_bertscore_f1": 0.8982078865170479,
        "std_bertscore_f1": 0.07770796752111847,
        "avg_exact_match": 0.3375,
        "std_exact_match": 0.4728570079844434,
        "avg_token_f1": 0.500917134855896,
        "std_token_f1": 0.4092211035573432,
        "avg_rouge_l": 0.5047111521316616,
        "std_rouge_l": 0.4124699989288018
      },
      "seed_76": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "en",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7305971041942636,
        "std_semantic_similarity": 0.22846488266715786,
        "avg_bertscore_f1": 0.8852457250157992,
        "std_bertscore_f1": 0.0775265636377658,
        "avg_exact_match": 0.25833333333333336,
        "std_exact_match": 0.4377181995556299,
        "avg_token_f1": 0.419827733804471,
        "std_token_f1": 0.40430908029702567,
        "avg_rouge_l": 0.42472951769143336,
        "std_rouge_l": 0.4089447903127382
      }
    },
    "es": {
      "seed_42": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "es",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7117973292246461,
        "std_semantic_similarity": 0.2362632217187315,
        "avg_bertscore_f1": 0.8740964109698931,
        "std_bertscore_f1": 0.0767540271904056,
        "avg_exact_match": 0.2625,
        "std_exact_match": 0.43999289766995103,
        "avg_token_f1": 0.37408364079221995,
        "std_token_f1": 0.4141233648396919,
        "avg_rouge_l": 0.3812115419625586,
        "std_rouge_l": 0.4185795161063833
      },
      "seed_59": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "es",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.688633139214168,
        "std_semantic_similarity": 0.2346929370617495,
        "avg_bertscore_f1": 0.8691011428833008,
        "std_bertscore_f1": 0.07160535091120361,
        "avg_exact_match": 0.20833333333333334,
        "std_exact_match": 0.4061164310337068,
        "avg_token_f1": 0.3451896171976828,
        "std_token_f1": 0.3861983438720474,
        "avg_rouge_l": 0.3495129355495198,
        "std_rouge_l": 0.39089425652976056
      },
      "seed_76": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "es",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6976675902803738,
        "std_semantic_similarity": 0.23223362558053193,
        "avg_bertscore_f1": 0.8674333564937114,
        "std_bertscore_f1": 0.07334608003446531,
        "avg_exact_match": 0.20833333333333334,
        "std_exact_match": 0.40611643103370676,
        "avg_token_f1": 0.34744279957326696,
        "std_token_f1": 0.39638226031462803,
        "avg_rouge_l": 0.35159841388652685,
        "std_rouge_l": 0.3991974279998788
      }
    },
    "th": {
      "seed_42": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "th",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.722340729739517,
        "std_semantic_similarity": 0.25166779325657535,
        "avg_bertscore_f1": 0.9059987654288609,
        "std_bertscore_f1": 0.06945652726874733,
        "avg_exact_match": 0.24166666666666667,
        "std_exact_match": 0.42809331796804406,
        "avg_token_f1": 0.43125926461452774,
        "std_token_f1": 0.4104046514745951,
        "avg_rouge_l": 0.22819931430225548,
        "std_rouge_l": 0.40500301551414375
      },
      "seed_59": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "th",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7299607568110029,
        "std_semantic_similarity": 0.2399034184316073,
        "avg_bertscore_f1": 0.9075464621186257,
        "std_bertscore_f1": 0.07083541845597444,
        "avg_exact_match": 0.2708333333333333,
        "std_exact_match": 0.44439018766044885,
        "avg_token_f1": 0.4529071098818439,
        "std_token_f1": 0.4164717671589531,
        "avg_rouge_l": 0.2564896582175994,
        "std_rouge_l": 0.4159506238372819
      },
      "seed_76": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "th",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7222066641474764,
        "std_semantic_similarity": 0.23951534349037745,
        "avg_bertscore_f1": 0.9063978895545006,
        "std_bertscore_f1": 0.0676505039763269,
        "avg_exact_match": 0.24583333333333332,
        "std_exact_match": 0.4305801964275128,
        "avg_token_f1": 0.42857540850961906,
        "std_token_f1": 0.416894242496599,
        "avg_rouge_l": 0.2119955349231665,
        "std_rouge_l": 0.39026332389521645
      }
    },
    "ar": {
      "seed_42": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "ar",
        "seed": 42,
        "num_samples": 240,
        "avg_semantic_similarity": 0.68350647908325,
        "std_semantic_similarity": 0.23531832478162817,
        "avg_bertscore_f1": 0.8690680359800657,
        "std_bertscore_f1": 0.06228459775284457,
        "avg_exact_match": 0.15416666666666667,
        "std_exact_match": 0.36110844016106236,
        "avg_token_f1": 0.397108304558864,
        "std_token_f1": 0.3539712810346114,
        "avg_rouge_l": 0.14103294853294854,
        "std_rouge_l": 0.3183963197004582
      },
      "seed_59": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "ar",
        "seed": 59,
        "num_samples": 240,
        "avg_semantic_similarity": 0.6917852695720891,
        "std_semantic_similarity": 0.2282556044265052,
        "avg_bertscore_f1": 0.8683567141493161,
        "std_bertscore_f1": 0.06625722832414753,
        "avg_exact_match": 0.15833333333333333,
        "std_exact_match": 0.36505326856349185,
        "avg_token_f1": 0.40032459638186757,
        "std_token_f1": 0.3553876705999035,
        "avg_rouge_l": 0.15568903318903318,
        "std_rouge_l": 0.32636063940792
      },
      "seed_76": {
        "config_name": "incorrect_tag",
        "config_description": "Wrong-Tag_0-shot",
        "language": "ar",
        "seed": 76,
        "num_samples": 240,
        "avg_semantic_similarity": 0.7042535721013944,
        "std_semantic_similarity": 0.20751630135822044,
        "avg_bertscore_f1": 0.8650554617245992,
        "std_bertscore_f1": 0.06451466691884077,
        "avg_exact_match": 0.15416666666666667,
        "std_exact_match": 0.36110844016106236,
        "avg_token_f1": 0.4105979234252676,
        "std_token_f1": 0.3503407615857604,
        "avg_rouge_l": 0.15915011645274804,
        "std_rouge_l": 0.32650210788015993
      }
    }
  }
}